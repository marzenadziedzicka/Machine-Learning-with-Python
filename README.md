# Machine-Learning-with-Python

* Decision Trees - sklearn.tree, DecisionTreeClassifier, download, read_csv, values, sklearn.preprocessing, LabelEncoder, fit, transform, predict, entropy,  sklearn.model_selection, train_test_split, format, sklearn.metrics.accuracy_score
* K-Nearest Neighbors - read_csv, value_counts, hist, columns, values, preprocessing.StandardScaler().fit(X).transform(X.astype(float)), sklearn.model_selection.train_test_split, sklearn.neighbors.KNeighborsClassifier.fit, predict, metrics.accuracy_score, np.std, max, argmax
* Logistic Regression with Python - read_csv, astype, np.asarray, sklearn.preprocessing.StandardScaler().fit(X).transform(X), sklearn.model_selection.train_test_split, sklearn.linear_model.LogisticRegression.fit, predict, predict_proba, sklearn.metrics.confusion_matrix, sklearn.metrics.jaccard_score, np.set_printoptions, classification_report. log_loss
* SVM (Support Vector Machines) - svm.SVC,train_test_split, fit, predict, classification_report, confusion_matrix, np.set_printoptions, f1_score, jaccard_score, pd.to_numeric, notnull, dtypes, np.asarray
* K-Means Clustering -  KMeans, make_blobs, fit, labels_, cluster_centers_, StandardScaler, plt.cm.Spectral, Axes3D, np.random.seed, plt.scatter, fit_transform, np.nan_to_num, groupby, mean
* Multiple Linear Regression- read_csv, scatter, np.random.rand, linear_model.LinearRegression(), np.asanyarray, fit, predict, mean, score
* Simple Linear Regression - read_csv, describe, hist, scatter, np.random.rand, train, test, linear_model.LinearRegression(), np.asanyarray, fit, coef_, intercept_, predict, Mean Absolute Error (np.mean(np.absolute)), Mean Squared Error (np.mean..), R-squared(r2_score)
* Softmax Regression ,One-vs-All & One-vs-One for Multi-class Classification - SVC, LogisticRegression, accuracy_score, predict_proba, argmax, predict, fit
* Regression Trees - DecisionTreeRegressor, train_test_split, fit, score, predict, isna().sum(), dropna, drop 
* Final Project: Classification with Python - Linear Regression, KNN, Decision Trees, Logistic Regression, SVM, Accuracy Score, Jaccard Index, F1-Score, LogLoss, Mean Absolute Error, Mean Squared Error, R2-Score, get_dummies, One Hot Encoding
* Scikit-Learn and Snap ML - train_test_split, normalize, StandardScaler, compute_sample_weight, roc_auc_score, unique, value_counts, values, hist, sklearn.tree.DecisionTreeClassifier, snapml.DecisionTreeClassifier, predict_proba, sklearn.svm.LinearSVC, snapml.SupportVectorMachine
* Scikit-Learn and Snap ML 2 - train_test_split, normalize, StandardScaler, compute_sample_weight, pd.to_datetime, .hour, .weekday, get_dummies, sklearn.tree.DecisionTreeRegressor, snapml.DecisionTreeRegressor, fit, predict, mean_squared_error
